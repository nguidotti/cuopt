# Copyright (c) 2025, NVIDIA CORPORATION.
schema_version: 1

context:
  version: ${{ env.get("RAPIDS_PACKAGE_VERSION") }}
  minor_version: ${{ (version | split("."))[:2] | join(".") }}
  cuda_version: ${{ (env.get("RAPIDS_CUDA_VERSION") | split("."))[:2] | join(".") }}
  cuda_major: '${{ (env.get("RAPIDS_CUDA_VERSION") | split("."))[0] }}'
  date_string: '${{ env.get("RAPIDS_DATE_STRING") }}'
  py_version: ${{ env.get("RAPIDS_PY_VERSION") }}
  py_buildstring: ${{ py_version | version_to_buildstring }}
  head_rev: '${{ git.head_rev(".")[:8] }}'

package:
  name: cuopt
  version: ${{ version }}

source:
  path: ../../..

build:
  string: cuda${{ cuda_major }}_py${{ py_buildstring }}_${{ date_string }}_${{ head_rev }}
  dynamic_linking:
    overlinking_behavior: error
  prefix_detection:
    # See https://github.com/rapidsai/build-planning/issues/160
    # Blanket ignore here as there are quite a few shared objects shipped in cuopt
    ignore_binary_files: True
  script:
    content: |
      ./build.sh cuopt
    secrets:
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY
      - AWS_SESSION_TOKEN
    env:
      CMAKE_C_COMPILER_LAUNCHER: ${{ env.get("CMAKE_C_COMPILER_LAUNCHER") }}
      CMAKE_CUDA_COMPILER_LAUNCHER: ${{ env.get("CMAKE_CUDA_COMPILER_LAUNCHER") }}
      CMAKE_CXX_COMPILER_LAUNCHER: ${{ env.get("CMAKE_CXX_COMPILER_LAUNCHER") }}
      CMAKE_GENERATOR: ${{ env.get("CMAKE_GENERATOR") }}
      SCCACHE_BUCKET: ${{ env.get("SCCACHE_BUCKET") }}
      SCCACHE_IDLE_TIMEOUT: ${{ env.get("SCCACHE_IDLE_TIMEOUT") }}
      SCCACHE_REGION: ${{ env.get("SCCACHE_REGION") }}
      SCCACHE_S3_USE_SSL: ${{ env.get("SCCACHE_S3_USE_SSL") }}
      SCCACHE_S3_NO_CREDENTIALS: ${{ env.get("SCCACHE_S3_NO_CREDENTIALS") }}
      SCCACHE_S3_KEY_PREFIX: cuopt/${{ env.get("RAPIDS_CONDA_ARCH") }}/cuda${{ cuda_major }}

requirements:
  build:
    - cmake ${{ cmake_version }}
    - ninja
    - ${{ compiler("c") }}
    - ${{ compiler("cxx") }}
    - ${{ compiler("cuda") }}
    - cuda-version =${{ cuda_version }}
    - ${{ stdlib("c") }}
  host:
    - cuda-version =${{ cuda_version }}
    - cython >=3.0.0
    - libcuopt =${{ version }}
    - pip
    - pylibraft =${{ minor_version }}
    - python =${{ py_version }}
    - rapids-build-backend >=0.4.0,<0.5.0.dev0
    - rmm =${{ minor_version }}
    - scikit-build-core >=0.10.0
    - cuda-cudart-dev
    - if: cuda_major == "12"
      then: cuda-python >=12.9.2,<13.0a0
      else: cuda-python >=13.0.1,<14.0a0
  run:
    - ${{ pin_compatible("cuda-version", upper_bound="x", lower_bound="x") }}
    - cudf =${{ minor_version }}
    - cuopt-mps-parser =${{ version }}
    - cupy >=13.6.0
    - cuvs =${{ minor_version }}
    - h5py
    - libcuopt =${{ version }}
    - numba >=0.60.0
    - numba-cuda>=0.19.1,<0.20.0a0
    - numpy >=1.23,<3.0a0
    - pandas >=2.0
    - pylibraft =${{ minor_version }}
    - python
    - raft-dask =${{ minor_version }}
    - rapids-dask-dependency =${{ minor_version }}
    - rmm =${{ minor_version }}
    # Needed by Numba for CUDA support
    - cuda-nvcc-impl
    # TODO: Add nvjitlink here
    # xref: https://github.com/rapidsai/cudf/issues/12822
    - if: cuda_major == "12"
      then: cuda-python >=12.9.2,<13.0a0
      else: cuda-python >=13.0.1,<14.0a0
  ignore_run_exports:
    by_name:
      - cuda-cudart
      - cuda-version

tests:
  - python:
      imports:
        - cuopt
      pip_check: false

about:
  homepage: ${{ load_from_file("python/cuopt/pyproject.toml").project.urls.Homepage }}
  license: ${{ load_from_file("python/cuopt/pyproject.toml").project.license.text }}
  summary: ${{ load_from_file("python/cuopt/pyproject.toml").project.description }}
